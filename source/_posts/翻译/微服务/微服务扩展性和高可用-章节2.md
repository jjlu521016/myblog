---
title: 微服务扩展性和高可用-章节2
tags:
  - '翻译 '
  - 微服务
toc: true
categories:
  - 翻译
  - 微服务
date: 2019-05-09 13:28:08
---

> 原文出处:https://dzone.com/refcardz/scalability?chapter=2
## Implementing Scalable Systems
SLAs determine whether systems must scale up or out. They also drive the growth timeline. A stock trading system must scale in real-time within minimum and maximum availability levels. An e-commerce system, in contrast, may scale in during the "slow" months of the year, and scale out during the retail holiday season to satisfy much larger demand.

### Load Balancing
Load balancing is a technique for minimizing response time and maximizing throughput by spreading requests among two or more resources. Load balancers may be implemented in dedicated hardware devices, or in software. Figure 3 shows how load-balanced systems appear to the resource consumers as a single resource exposed through a well-known address. The load balancer is responsible for routing requests to available systems based on a scheduling rule.

![image.png](/images/2019/05/09/c0a9f230-721a-11e9-b22a-7d284106ced1.png)

***Figure 3: Availability as percentage of Total Yearly Uptime***

Scheduling rules are algorithms for determining which server must service a request. Web applications and services are typically balanced by following round robin scheduling rules, but can also balance based on least-connected, IP-hash, or a number of other options. Caching pools are balanced by applying frequency rules and expiration algorithms. Applications where stateless requests arrive with a uniform probability for any number of servers may use a pseudo-random scheduler. Applications like music stores, where some content is statistically more popular, may use asymmetric load balancers to shift the larger number popular requests to higher performance systems, serving the rest of the requests from less powerful systems or clusters.

### Persistent Load Balancers
Stateful applications require persistent or sticky load balancing, where a consumer is guaranteed to maintain a session with a specific server from the pool. Figure 4 shows a sticky balancer that maintains sessions from multiple clients. Figure 5 shows how the cluster maintains sessions by sharing data using a database.

![image.png](/images/2019/05/09/e6e67590-721a-11e9-b22a-7d284106ced1.png)
***Figure 4: Sticky Load Balancer***

### Common Features of a Load Balancer
Asymmetric load distribution – assigns some servers to handle a bigger load than others

+ Content filtering: Inbound or outbound.
+ Distributed Denial of Services (DDoS) attack protection
+ Firewall.
+ Payload switching: Sends requests to different servers based on URI, port, and/or protocol.
+ Priority activation: Adds standing by servers to the pool.
+ Rate shaping: Ability to give different priority to different traffic.
+ Scripting: Reduces human interaction by implementing programming rules or actions.
+ SSL termination: Hardware-assisted encryption frees web server resources.
+ TCP buffering and offloading: Throttle requests to servers in the pool.
+ GZIP compression: Decreases transfer bandwidth utilization.
![image.png](/images/2019/05/09/186c3960-721b-11e9-b22a-7d284106ced1.png)
***Figure 5: Database Sessions***